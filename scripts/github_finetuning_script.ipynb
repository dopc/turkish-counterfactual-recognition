{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kesUzY4B3vb"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets sacremoses accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwtLCyvOgWS4"
   },
   "outputs": [],
   "source": [
    "%cd <path_to_running_code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6RipdigVQCi"
   },
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "lr = 1e-05\n",
    "max_seq_len = 256\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNVUaEDlZ7Dn"
   },
   "outputs": [],
   "source": [
    "## give the dataset paths\n",
    "amcd_path = ''\n",
    "semeval_path = ''\n",
    "trcd_path = ''\n",
    "\n",
    "data_path_dict = {\n",
    "  'amz_en': {\n",
    "      'train': f'{amcd_path}/data/EN-ext_train.tsv',\n",
    "      'eval': f'{amcd_path}/data/EN-ext_valid.tsv',\n",
    "      'test': f'{amcd_path}/data/EN-ext_test.tsv'\n",
    "  },\n",
    "  'amz_de': {\n",
    "      'train': f'{amcd_path}/data/DE_train.tsv',\n",
    "      'eval': f'{amcd_path}/data/DE_valid.tsv',\n",
    "      'test': f'{amcd_path}/data/DE_test.tsv'\n",
    "  },\n",
    "  'amz_jp': {\n",
    "      'train': f'{amcd_path}/data/JP_train.tsv',\n",
    "      'eval': f'{amcd_path}/data/JP_valid.tsv',\n",
    "      'test': f'{amcd_path}/data/JP_test.tsv'\n",
    "  },\n",
    "    'semeval': {\n",
    "      'train': f'{semeval_path}/Subtask-1/subtask1_train_train.csv', # 90% of original train\n",
    "      'eval': f'{semeval_path}/Subtask-1/subtask1_train_eval.csv', # 10% of original eval\n",
    "      'test': f'{semeval_path}/Subtask-1/subtask1_test.csv'\n",
    "  },\n",
    "    'tr': {\n",
    "      'train': f'{trcd_path}/train.csv',\n",
    "      'eval': f'{trcd_path}/valid.csv',\n",
    "      'test': f'{trcd_path}/test.csv'\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWXGvOa-Z3-6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_field_dict = {\n",
    "  'amz_en': {\n",
    "    'text': 'sentence',\n",
    "    'label': 'is_counterfactual'\n",
    "  },\n",
    "    'amz_de': {\n",
    "    'text': 'sentence',\n",
    "    'label': 'is_counterfactual'\n",
    "  },\n",
    "    'amz_jp': {\n",
    "    'text': 'sentence',\n",
    "    'label': 'is_counterfactual'\n",
    "  },\n",
    "  'semeval': {\n",
    "    'text': 'sentence',\n",
    "    'label': 'gold_label'\n",
    "  },\n",
    "  'tr': {\n",
    "    'text': 'sentence',\n",
    "    'label': 'label'\n",
    "  }\n",
    "}\n",
    "\n",
    "tr_cw2re_dict = {'-mAlIydI': '(?i)(?<=\\\\w)malıydı|(?<=\\\\w)meliydi',\n",
    " '-sA': '(?i)(?<=\\\\w)sa|(?<=\\\\w)se',\n",
    " '-sAlArDI': '(?i)(?<=\\\\w)salardı|(?<=\\\\w)selerdi',\n",
    " '-AydI': '(?i)(?<=\\\\w)aydı|(?<=\\\\w)eydi|(?<=\\\\w)saydı|(?<=\\\\w)seydi',\n",
    " '-AymIş': '(?i)(?<=\\\\w)aymış|(?<=\\\\w)eymiş|(?<=\\\\w)saymış|(?<=\\\\w)seymiş',\n",
    " '-ArdI': '(?i)(?<=\\\\w)ardı|(?<=\\\\w)erdi|(?<=\\\\w)ırdı|(?<=\\\\w)irdi|(?<=\\\\w)urdu|(?<=\\\\w)ürdü',\n",
    " '-AcAkDI': '(?i)(?<=\\\\w)acaktı|(?<=\\\\w)ecekti',\n",
    " '-AmAz-DI': '(?i)(?<=\\\\w)amazdı|(?<=\\\\w)emezdi',\n",
    " '-mAz-DI': '(?i)(?<=\\\\w)mazdı|(?<=\\\\w)mezdi',\n",
    " '-Abil-Ar-DI': '(?i)(?<=\\\\w)abilirdi|(?<=\\\\w)ebilirdi'}\n",
    "\n",
    "def get_csv_tsv_data(data_path):\n",
    "  if '.tsv' in data_path:\n",
    "    return pd.read_csv(data_path, sep='\\t')\n",
    "  return pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fn7l2e5aRW-C"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def get_clue_words(lang):\n",
    "  with open(f'{amcd_path}clue_words/counterfactual_clue_words_{lang}.txt') as f:\n",
    "      clue_words = f.readlines()\n",
    "  return [clue_word.strip() for clue_word in clue_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eirktUcw0Z2q"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def mask_cw(df, clue_words, text_field, mask_token):\n",
    "  masked_sentences = []\n",
    "  for text in df[text_field].values:\n",
    "    for clue_word in clue_words:\n",
    "      text = re.sub(fr'{clue_word}', mask_token, text)\n",
    "    masked_sentences.append(text)\n",
    "  df['masked_text'] = masked_sentences\n",
    "  return df\n",
    "\n",
    "def mask_cw_tr(df, clue_words, mask_token):\n",
    "  def helper_mask_cw_tr(row, mapping):\n",
    "      pattern = r'%s' % mapping.get(row['CW'], None)\n",
    "      subbed = re.sub(pattern, mask_token, row['text'])\n",
    "      return subbed\n",
    "  df['masked_text'] = df.apply(lambda x: helper_mask_cw_tr(x, clue_words), axis=1)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lIO-KOCsbmsB"
   },
   "outputs": [],
   "source": [
    "def normalize_df(df, field_dict, masking=False):\n",
    "  text_field = field_dict['text']\n",
    "  label_field = field_dict['label']\n",
    "  column_selector = [text_field, label_field]\n",
    "  if masking:\n",
    "    column_selector = ['masked_text'] + column_selector\n",
    "  df = df[column_selector]\n",
    "  return df.rename(columns={text_field: 'text',\n",
    "                            label_field: 'label'})\n",
    "def get_train_df(mapping, masking_strategy, mask_token, test_df_len=None):\n",
    "  dfs = []\n",
    "  for name, mask in mapping.items():\n",
    "    if mask:\n",
    "      df = get_csv_tsv_data(data_path_dict[name]['train'])\n",
    "      if masking_strategy:\n",
    "        if name == 'tr':\n",
    "          df = mask_cw_tr(df, tr_cw2re_dict, mask_token)\n",
    "        else:\n",
    "          lang = 'en' if name == 'semeval' else name.split('_')[-1]\n",
    "          df = mask_cw(df, get_clue_words(lang), data_field_dict[name]['text'], mask_token)\n",
    "      normalized_df = normalize_df(df, data_field_dict[name], masking_strategy)\n",
    "      dfs.append(normalized_df)\n",
    "  if test_df_len:\n",
    "    return pd.concat(dfs).sample(test_df_len, random_state=seed)\n",
    "  return pd.concat(dfs)\n",
    "\n",
    "def get_eval_df(mapping, test_df_len=None):\n",
    "  dfs = []\n",
    "  for name, mask in mapping.items():\n",
    "    if mask:\n",
    "      df = get_csv_tsv_data(data_path_dict[name]['eval'])\n",
    "      normalized_df = normalize_df(df, data_field_dict[name])\n",
    "      dfs.append(normalized_df)\n",
    "  if test_df_len:\n",
    "    return pd.concat(dfs).sample(test_df_len, random_state=seed)\n",
    "  return pd.concat(dfs)\n",
    "\n",
    "def get_test_df(name):\n",
    "  df = get_csv_tsv_data(data_path_dict[name]['test'])\n",
    "  normalized_df = normalize_df(df, data_field_dict[name])\n",
    "  return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3WDtClWrFtp0"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from typing import List\n",
    "\n",
    "class CFDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            data: pd.DataFrame,\n",
    "            tokenizer,\n",
    "            labels: List[str],\n",
    "            max_token_len: int = 256,\n",
    "            text_field: str = 'text',\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token_len = max_token_len\n",
    "        self.labels = labels\n",
    "        self.text_field = text_field\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "\n",
    "        text = data_row[self.text_field]\n",
    "        labels = data_row[self.labels]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "            text=text,\n",
    "            input_ids=encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "            labels=torch.tensor(labels, dtype=torch.long)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBx56tttm0TG"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "train_datasets = []\n",
    "options = ['amz_en', 'amz_de', 'amz_jp', 'semeval', 'tr']\n",
    "for L in [\n",
    "    1,\n",
    "    # 2,\n",
    "    # 3,\n",
    "    # 4,\n",
    "    # 5\n",
    "    ]:\n",
    "    for subset in itertools.combinations(options, L):\n",
    "        train_datasets.append(list(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueYxEyOuGY7u"
   },
   "outputs": [],
   "source": [
    "\"\"\" USED MODELS\n",
    "\n",
    "bert-base-multilingual-uncased\n",
    "xlm-roberta-base\n",
    "dbmdz/bert-base-turkish-cased\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from sklearn.metrics import recall_score\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers import Trainer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, f1_score\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, AutoConfig, set_seed\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "_EXPERIMENT_NAME = 'demo'\n",
    "_MODEL_SUFFIX_SUFFIX = ''\n",
    "\n",
    "EARLY_STOP_PATIENCE = 1\n",
    "EPOCH_N = 50\n",
    "\n",
    "_MASKS = [False, True]\n",
    "_MODEL_PATHS = [\n",
    "    'bert-base-multilingual-uncased',\n",
    "    'xlm-roberta-base',\n",
    "    'dbmdz/bert-base-turkish-cased'\n",
    "    ]\n",
    "_TRAIN_DATASETS = train_datasets\n",
    "\n",
    "test_data_filter = [\n",
    "    'amz_en',\n",
    "    'amz_de',\n",
    "    'amz_jp',\n",
    "    'semeval',\n",
    "    'tr',\n",
    "]\n",
    "_OVERWRITE = True\n",
    "\n",
    "\n",
    "i = 0\n",
    "for TRAIN_DATASETS in _TRAIN_DATASETS:\n",
    "  for MASK in _MASKS:\n",
    "    for MODEL_PATH in _MODEL_PATHS:\n",
    "        for test_data_name in test_data_filter:\n",
    "\n",
    "        i += 1\n",
    "        total = len(_MASKS) * len(_MODEL_PATHS) * len(_TRAIN_DATASETS) * len(test_data_filter)\n",
    "        model_name = MODEL_PATH.split('/')[-1]\n",
    "        train_datasets_name = '-'.join(TRAIN_DATASETS)\n",
    "        model_suffix = f'mask={MASK}_train={train_datasets_name}{_MODEL_SUFFIX_SUFFIX}'\n",
    "\n",
    "        run_name = f\"{model_name} {model_suffix}\"\n",
    "\n",
    "        run_dir = f\"./thesis/{_EXPERIMENT_NAME}/best_trHP/model={model_name}_{model_suffix}\"\n",
    "\n",
    "        if os.path.exists(os.path.join(run_dir, 'results/tr')):\n",
    "          if _OVERWRITE:\n",
    "            print(f'\\n----->>>>> OVERWRITING: {run_name}\\n')\n",
    "          else:\n",
    "            print(f'\\n----->>>>> SKIPPING: {run_name}\\n')\n",
    "            continue\n",
    "        print(f'--> RUNNING (test: {test_data_name}) : {run_name}')\n",
    "\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "\n",
    "        train_data_filter = {\n",
    "            'amz_en': False,\n",
    "            'amz_de': False,\n",
    "            'amz_jp': False,\n",
    "            'semeval': False,\n",
    "            'tr': False\n",
    "        }\n",
    "        # get_data_dfs\n",
    "        for name in TRAIN_DATASETS:\n",
    "          train_data_filter[name] = True\n",
    "\n",
    "        # get train split of the test dataset to dataset scaling\n",
    "        test_train_data_len = len(get_train_df({test_data_name: True}, False, tokenizer.pad_token))\n",
    "        # get actual train dataset split with scaling, no scaling if train-test dataset is the same\n",
    "        train_df = get_train_df(train_data_filter, MASK, tokenizer.pad_token, test_train_data_len)\n",
    "\n",
    "        if MASK:\n",
    "          s = train_df[train_df.masked_text.str.contains(tokenizer.pad_token[1:-1])].sample(1)\n",
    "          sample_text = s.text.values[0]\n",
    "          sample_masked_text = s.masked_text.values[0]\n",
    "          print(f'\\n\\n\\n--- before masking: {sample_text}')\n",
    "          print(f'--- after masking: {sample_masked_text}\\n\\n\\n')\n",
    "\n",
    "          print(f'\\n--- before masking: {tokenizer.encode(sample_text)}')\n",
    "          print(f'--- after masking: {tokenizer.encode(sample_masked_text)}\\n\\n\\n')\n",
    "\n",
    "        test_eval_df_len = len(get_eval_df({test_data_name: True}))\n",
    "        eval_df = get_eval_df(train_data_filter, test_eval_df_len)\n",
    "\n",
    "        print(f'train dataset {len(train_df)} for {train_datasets_name}')\n",
    "        print(f'validation dataset {len(eval_df)} for {train_datasets_name}')\n",
    "\n",
    "        text_field = 'text'\n",
    "        label_field = 'label'\n",
    "\n",
    "        ## crete datasets\n",
    "        train_dataset = CFDataset(\n",
    "            train_df,\n",
    "            tokenizer,\n",
    "            max_token_len=max_seq_len,\n",
    "            labels=[label_field],\n",
    "            text_field=text_field if not MASK else 'masked_text',\n",
    "        )\n",
    "\n",
    "        eval_dataset = CFDataset(\n",
    "            eval_df,\n",
    "            tokenizer,\n",
    "            max_token_len=max_seq_len,\n",
    "            labels=[label_field],\n",
    "            text_field=text_field,\n",
    "        )\n",
    "\n",
    "        ## trainer\n",
    "        metric = load_metric(\"f1\")\n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            predictions = np.argmax(logits, axis=-1)\n",
    "            return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=run_dir,\n",
    "            learning_rate=lr,\n",
    "            per_device_train_batch_size=train_batch_size,\n",
    "            seed=seed,\n",
    "            logging_dir='./logs',\n",
    "            logging_steps=10,\n",
    "            num_train_epochs=EPOCH_N,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_total_limit = 1,\n",
    "            load_best_model_at_end=True, # use eval_loss\n",
    "            metric_for_best_model='eval_loss',\n",
    "            save_strategy = \"epoch\",\n",
    "            report_to='none'\n",
    "        )\n",
    "\n",
    "        early_callback = EarlyStoppingCallback(early_stopping_patience=EARLY_STOP_PATIENCE)\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=eval_dataset,\n",
    "            compute_metrics=compute_metrics,\n",
    "            callbacks=[early_callback],\n",
    "          )\n",
    "        print(f\"\\n -----> RUNNING {i}th/{total} run\\n\")\n",
    "\n",
    "        ## train\n",
    "        trainer.train()\n",
    "\n",
    "\n",
    "        ## test\n",
    "        print(TRAIN_DATASETS, test_data_name)\n",
    "        ## test datasets\n",
    "        test_df = get_test_df(test_data_name)\n",
    "        print(f'test dataset {len(test_df)} for {test_data_name}')\n",
    "        test_dataset = CFDataset(\n",
    "            test_df,\n",
    "            tokenizer,\n",
    "            max_token_len=max_seq_len,\n",
    "            labels=[label_field],\n",
    "            text_field=text_field,\n",
    "        )\n",
    "\n",
    "        ## predict\n",
    "        result = trainer.predict(test_dataset)\n",
    "\n",
    "        ## get_result\n",
    "        predictions = np.argmax(result[0], axis=1)\n",
    "        gold_labels = test_dataset.data[label_field].values\n",
    "        test_df = test_dataset.data\n",
    "        test_df['prediction']  = predictions\n",
    "\n",
    "        ## create result path\n",
    "        result_path = os.path.join(run_dir, f'results/{test_data_name}')\n",
    "        if not os.path.exists(result_path):\n",
    "            os.makedirs(result_path)\n",
    "        test_df.to_csv(os.path.join(result_path, 'predictions.csv'), index=False)\n",
    "\n",
    "        ## clf report\n",
    "        report = classification_report(y_true=gold_labels, y_pred=predictions)\n",
    "        # print(report)\n",
    "        with open(os.path.join(result_path, 'classification_report.txt'), 'w') as f:\n",
    "            f.write(report)\n",
    "\n",
    "        ## metrics\n",
    "        metric_dict = {\n",
    "        'f1_macro': f1_score(gold_labels, predictions, average='macro'),\n",
    "        'mcc': matthews_corrcoef(gold_labels, predictions),\n",
    "        'acc': accuracy_score(gold_labels, predictions),\n",
    "        # '----': '----',\n",
    "        'f1_default': f1_score(gold_labels, predictions),\n",
    "        'f1_weighted': f1_score(gold_labels, predictions, average='weighted'),\n",
    "        }\n",
    "        print(metric_dict)\n",
    "\n",
    "        with open(os.path.join(result_path, 'metrics.json'), 'w') as fp:\n",
    "          json.dump(metric_dict, fp)\n",
    "\n",
    "        ## confusion matrix\n",
    "        cm = confusion_matrix(y_true=gold_labels, y_pred=predictions)\n",
    "        df_cm = pd.DataFrame(\n",
    "            cm,\n",
    "            index = ['Not CF', 'CF'],\n",
    "            columns = ['Not CF', 'CF']\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize = (10,7))\n",
    "        sn.heatmap(df_cm, annot=True, cmap='Blues', fmt='g')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.savefig(os.path.join(result_path, 'confusion_matrix.png'))\n",
    "        plt.close()\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
